{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from keras.datasets import imdb\n",
    "from keras import layers\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_date</th>\n",
       "      <th>headline_category</th>\n",
       "      <th>headline_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20010101</td>\n",
       "      <td>sports.wwe</td>\n",
       "      <td>win over cena satisfying but defeating underta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20010102</td>\n",
       "      <td>bollywood</td>\n",
       "      <td>Raju Chacha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20010102</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Status quo will not be disturbed at Ayodhya; s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20010102</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Fissures in Hurriyat over Pak visit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20010102</td>\n",
       "      <td>unknown</td>\n",
       "      <td>America's unwanted heading for India?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   publish_date headline_category  \\\n",
       "0      20010101        sports.wwe   \n",
       "1      20010102         bollywood   \n",
       "2      20010102           unknown   \n",
       "3      20010102           unknown   \n",
       "4      20010102           unknown   \n",
       "\n",
       "                                       headline_text  \n",
       "0  win over cena satisfying but defeating underta...  \n",
       "1                                        Raju Chacha  \n",
       "2  Status quo will not be disturbed at Ayodhya; s...  \n",
       "3                Fissures in Hurriyat over Pak visit  \n",
       "4              America's unwanted heading for India?  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path=\"C:/Users/Apar/Desktop/india-news-headlines.csv\"\n",
    "df=pd.read_csv(path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2969922, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[df.headline_category!='unknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[:20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_date</th>\n",
       "      <th>headline_category</th>\n",
       "      <th>headline_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20010101</td>\n",
       "      <td>sports.wwe</td>\n",
       "      <td>win over cena satisfying but defeating underta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20010102</td>\n",
       "      <td>bollywood</td>\n",
       "      <td>Raju Chacha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>20010103</td>\n",
       "      <td>entertainment.hindi.bollywood.news</td>\n",
       "      <td>'Devdas': Jinxed?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>20010104</td>\n",
       "      <td>business.india-business</td>\n",
       "      <td>Car dealers caught in Bihar sales tax ruling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>20010104</td>\n",
       "      <td>city.bengaluru</td>\n",
       "      <td>He's not so inscrutable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     publish_date                   headline_category  \\\n",
       "0        20010101                          sports.wwe   \n",
       "1        20010102                           bollywood   \n",
       "87       20010103  entertainment.hindi.bollywood.news   \n",
       "128      20010104             business.india-business   \n",
       "129      20010104                      city.bengaluru   \n",
       "\n",
       "                                         headline_text  \n",
       "0    win over cena satisfying but defeating underta...  \n",
       "1                                          Raju Chacha  \n",
       "87                                   'Devdas': Jinxed?  \n",
       "128       Car dealers caught in Bihar sales tax ruling  \n",
       "129                            He's not so inscrutable  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.headline_category.nunique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=list(df.headline_category.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sports.wwe\n",
      "bollywood\n",
      "entertainment.hindi.bollywood.news\n",
      "business.india-business\n",
      "city.bengaluru\n",
      "city.delhi\n",
      "city.patna\n",
      "hollywood\n",
      "india\n",
      "sports.cricket.news\n",
      "sports.football\n",
      "only-in-america\n",
      "city.ahmedabad\n",
      "jugular-vein\n",
      "swaminomics\n",
      "city.thiruvananthapuram\n",
      "city.chandigarh\n",
      "city.mumbai\n",
      "city.pune\n",
      "home.science\n",
      "city.kolkata\n",
      "city.lucknow\n",
      "city.hyderabad\n",
      "cricket\n",
      "business.international-business\n",
      "removed\n",
      "entertainment.english.hollywood.news\n",
      "off-the-cuff\n",
      "home.sunday-times.deep-focus\n",
      "bombay-times\n",
      "india-in-lanka\n",
      "home.sunday-times.all-that-matters\n",
      "talking-terms\n",
      "home.education\n",
      "pune-times\n",
      "calcutta-times\n",
      "hyderabad-times\n",
      "bangalore-times\n",
      "delhi-times\n",
      "lucknow-times\n"
     ]
    }
   ],
   "source": [
    "for i in k:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (df.shape[0]):\n",
    "   # df.loc[1].at['B']\n",
    "    j=df['headline_category'].iloc[i].split(\".\")\n",
    "    df['headline_category'].iloc[i]=j[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=list(df.headline_category.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sports\n",
      "bollywood\n",
      "entertainment\n",
      "business\n",
      "city\n",
      "hollywood\n",
      "india\n",
      "only-in-america\n",
      "jugular-vein\n",
      "swaminomics\n",
      "home\n",
      "cricket\n",
      "removed\n",
      "off-the-cuff\n",
      "bombay-times\n",
      "india-in-lanka\n",
      "talking-terms\n",
      "pune-times\n",
      "calcutta-times\n",
      "hyderabad-times\n",
      "bangalore-times\n",
      "delhi-times\n",
      "lucknow-times\n"
     ]
    }
   ],
   "source": [
    "c=0\n",
    "for i in k:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxi=0\n",
    "for i in range (df.shape[0]):\n",
    "   # df.loc[1].at['B']\n",
    "    j=len(df['headline_text'].iloc[i].split(\" \"))\n",
    "    if maxi<j:\n",
    "        maxi=j\n",
    "maxi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 7)\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 1 5]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "df['headline_text'] = df['headline_text'].apply(lambda x: x.lower())\n",
    "df['headline_text'] = df['headline_text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))\n",
    "    \n",
    "max_fatures = 14\n",
    "tokenizer = Tokenizer(nb_words=max_fatures, split=' ')\n",
    "tokenizer.fit_on_texts(df['headline_text'].values)\n",
    "x = tokenizer.texts_to_sequences(df['headline_text'].values)\n",
    "x = pad_sequences(x)\n",
    "print(x.shape)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = x.shape[1]\n",
    "y = pd.get_dummies(df['headline_category']).values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training samples: (14000, 7) (14000, 23)\n",
      "Shape of testing samples: (6000, 7) (6000, 23)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.3, random_state = 42)\n",
    "print('Shape of training samples:',x_train.shape,y_train.shape)\n",
    "print('Shape of testing samples:',x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 32)                256       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 23)                2967      \n",
      "=================================================================\n",
      "Total params: 7,447\n",
      "Trainable params: 7,447\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32,input_dim=input_dim, activation='relu'))\n",
    "model.add(Dense(128))\n",
    "model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "14000/14000 [==============================] - 1s 48us/step - loss: 1.5821 - acc: 0.6363 - val_loss: 1.4073 - val_acc: 0.6398\n",
      "Epoch 2/10\n",
      "14000/14000 [==============================] - 0s 29us/step - loss: 1.4074 - acc: 0.6412 - val_loss: 1.3989 - val_acc: 0.6400\n",
      "Epoch 3/10\n",
      "14000/14000 [==============================] - 0s 29us/step - loss: 1.3993 - acc: 0.6414 - val_loss: 1.3955 - val_acc: 0.6400\n",
      "Epoch 4/10\n",
      "14000/14000 [==============================] - 0s 29us/step - loss: 1.3940 - acc: 0.6412 - val_loss: 1.3832 - val_acc: 0.6402\n",
      "Epoch 5/10\n",
      "14000/14000 [==============================] - 0s 29us/step - loss: 1.3887 - acc: 0.6413 - val_loss: 1.3862 - val_acc: 0.6402\n",
      "Epoch 6/10\n",
      "14000/14000 [==============================] - 0s 33us/step - loss: 1.3840 - acc: 0.6414 - val_loss: 1.3858 - val_acc: 0.6402\n",
      "Epoch 7/10\n",
      "14000/14000 [==============================] - 0s 31us/step - loss: 1.3823 - acc: 0.6411 - val_loss: 1.3811 - val_acc: 0.6402\n",
      "Epoch 8/10\n",
      "14000/14000 [==============================] - 1s 42us/step - loss: 1.3806 - acc: 0.6414 - val_loss: 1.3772 - val_acc: 0.6402\n",
      "Epoch 9/10\n",
      "14000/14000 [==============================] - 1s 38us/step - loss: 1.3799 - acc: 0.6414 - val_loss: 1.3809 - val_acc: 0.6402\n",
      "Epoch 10/10\n",
      "14000/14000 [==============================] - 0s 30us/step - loss: 1.3773 - acc: 0.6413 - val_loss: 1.3772 - val_acc: 0.6395\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=10,\n",
    "                     verbose=1,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18679"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 7, 100)            1867900   \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 700)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 128)               89728     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 23)                759       \n",
      "=================================================================\n",
      "Total params: 1,962,515\n",
      "Trainable params: 1,962,515\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 100 ,input_length = x.shape[1], dropout=0.2))\n",
    "model.add(layers.Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Dense(32))\n",
    "model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      " - 12s - loss: 1.4155 - acc: 0.6401 - val_loss: 1.3716 - val_acc: 0.6402\n",
      "Epoch 2/10\n",
      " - 11s - loss: 1.3661 - acc: 0.6412 - val_loss: 1.3909 - val_acc: 0.6402\n",
      "Epoch 3/10\n",
      " - 12s - loss: 1.3639 - acc: 0.6414 - val_loss: 1.3614 - val_acc: 0.6402\n",
      "Epoch 4/10\n",
      " - 12s - loss: 1.3590 - acc: 0.6412 - val_loss: 1.3676 - val_acc: 0.6402\n",
      "Epoch 5/10\n",
      " - 12s - loss: 1.3571 - acc: 0.6411 - val_loss: 1.3654 - val_acc: 0.6402\n",
      "Epoch 6/10\n",
      " - 12s - loss: 1.3557 - acc: 0.6411 - val_loss: 1.3606 - val_acc: 0.6402\n",
      "Epoch 7/10\n",
      " - 12s - loss: 1.3538 - acc: 0.6414 - val_loss: 1.3614 - val_acc: 0.6402\n",
      "Epoch 8/10\n",
      " - 12s - loss: 1.3525 - acc: 0.6415 - val_loss: 1.3585 - val_acc: 0.6397\n",
      "Epoch 9/10\n",
      " - 12s - loss: 1.3500 - acc: 0.6416 - val_loss: 1.3701 - val_acc: 0.6400\n",
      "Epoch 10/10\n",
      " - 12s - loss: 1.3518 - acc: 0.6414 - val_loss: 1.3802 - val_acc: 0.6402\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "history = model.fit(x_train, y_train, epochs = 10, batch_size=batch_size, verbose = 2, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_embedding_matrix(filepath, word_index, embedding_dim):\n",
    "    vocab_size = len(word_index) + 1  # Adding again 1 because of reserved 0 index\n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "    with open(filepath,encoding='UTF-8') as f:\n",
    "        for line in f:\n",
    "            word, *vector = line.split()\n",
    "            if word in word_index:\n",
    "                idx = word_index[word] \n",
    "                embedding_matrix[idx] = np.array(\n",
    "                    vector, dtype=np.float32)[:embedding_dim]\n",
    "\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "embedding_matrix = create_embedding_matrix(\n",
    "    'C:/Srishtee/Btech/Sem6/NLP/Assignment/word embeddings/glove.6B.100d.txt',\n",
    "    tokenizer.word_index, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 7, 100)            1867900   \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 700)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 128)               89728     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 23)                2967      \n",
      "=================================================================\n",
      "Total params: 1,960,595\n",
      "Trainable params: 92,695\n",
      "Non-trainable params: 1,867,900\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.Embedding(vocab_size, embedding_dim, \n",
    "                           weights=[embedding_matrix], \n",
    "                           input_length=x.shape[1], \n",
    "                           trainable=False))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(y_train.shape[1], activation='softmax'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "14000/14000 [==============================] - 1s 105us/step - loss: 0.1011 - acc: 0.9660 - val_loss: 0.0902 - val_acc: 0.9688\n",
      "Epoch 2/10\n",
      "14000/14000 [==============================] - 1s 80us/step - loss: 0.0901 - acc: 0.9688 - val_loss: 0.0903 - val_acc: 0.9687\n",
      "Epoch 3/10\n",
      "14000/14000 [==============================] - 1s 73us/step - loss: 0.0898 - acc: 0.9687 - val_loss: 0.0902 - val_acc: 0.9686\n",
      "Epoch 4/10\n",
      "14000/14000 [==============================] - 1s 80us/step - loss: 0.0894 - acc: 0.9689 - val_loss: 0.0902 - val_acc: 0.9686\n",
      "Epoch 5/10\n",
      "14000/14000 [==============================] - 1s 68us/step - loss: 0.0892 - acc: 0.9689 - val_loss: 0.0900 - val_acc: 0.9686\n",
      "Epoch 6/10\n",
      "14000/14000 [==============================] - 1s 67us/step - loss: 0.0890 - acc: 0.9689 - val_loss: 0.0903 - val_acc: 0.9687\n",
      "Epoch 7/10\n",
      "14000/14000 [==============================] - 1s 67us/step - loss: 0.0888 - acc: 0.9689 - val_loss: 0.0904 - val_acc: 0.9685\n",
      "Epoch 8/10\n",
      "14000/14000 [==============================] - 1s 67us/step - loss: 0.0886 - acc: 0.9690 - val_loss: 0.0903 - val_acc: 0.9684\n",
      "Epoch 9/10\n",
      "14000/14000 [==============================] - 1s 80us/step - loss: 0.0885 - acc: 0.9691 - val_loss: 0.0904 - val_acc: 0.9682\n",
      "Epoch 10/10\n",
      "14000/14000 [==============================] - 1s 65us/step - loss: 0.0884 - acc: 0.9690 - val_loss: 0.0904 - val_acc: 0.9684\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'to': 1,\n",
       " 'in': 2,\n",
       " 'for': 3,\n",
       " 'of': 4,\n",
       " 'on': 5,\n",
       " 'the': 6,\n",
       " 'a': 7,\n",
       " 'govt': 8,\n",
       " 'up': 9,\n",
       " 'at': 10,\n",
       " 'with': 11,\n",
       " 'from': 12,\n",
       " 'be': 13,\n",
       " 'is': 14,\n",
       " 'police': 15,\n",
       " 'over': 16,\n",
       " 'against': 17,\n",
       " 'no': 18,\n",
       " 'and': 19,\n",
       " 'not': 20,\n",
       " 'new': 21,\n",
       " 'rs': 22,\n",
       " 'india': 23,\n",
       " 'by': 24,\n",
       " 'city': 25,\n",
       " 'killed': 26,\n",
       " 'case': 27,\n",
       " 'bjp': 28,\n",
       " 'as': 29,\n",
       " 'out': 30,\n",
       " 'will': 31,\n",
       " 'it': 32,\n",
       " 'more': 33,\n",
       " 'meet': 34,\n",
       " 'power': 35,\n",
       " 'may': 36,\n",
       " 'hc': 37,\n",
       " 'centre': 38,\n",
       " 'into': 39,\n",
       " 'cm': 40,\n",
       " 'state': 41,\n",
       " 'us': 42,\n",
       " 'held': 43,\n",
       " 'get': 44,\n",
       " 'students': 45,\n",
       " 'its': 46,\n",
       " 'cong': 47,\n",
       " 'says': 48,\n",
       " 'probe': 49,\n",
       " 'water': 50,\n",
       " 'gets': 51,\n",
       " 'all': 52,\n",
       " '3': 53,\n",
       " 'two': 54,\n",
       " 'set': 55,\n",
       " 'chief': 56,\n",
       " 'soon': 57,\n",
       " 'has': 58,\n",
       " 'panel': 59,\n",
       " 'life': 60,\n",
       " 'strike': 61,\n",
       " 'back': 62,\n",
       " 'cr': 63,\n",
       " 'minister': 64,\n",
       " 'indian': 65,\n",
       " '2': 66,\n",
       " 'seeks': 67,\n",
       " 'sc': 68,\n",
       " 'take': 69,\n",
       " 'are': 70,\n",
       " 'today': 71,\n",
       " 'man': 72,\n",
       " 'go': 73,\n",
       " 'court': 74,\n",
       " 'issue': 75,\n",
       " 'after': 76,\n",
       " 'pm': 77,\n",
       " 'plan': 78,\n",
       " 'an': 79,\n",
       " 'have': 80,\n",
       " 'about': 81,\n",
       " 'down': 82,\n",
       " 'teachers': 83,\n",
       " 'pak': 84,\n",
       " 'cbi': 85,\n",
       " 'help': 86,\n",
       " 'plea': 87,\n",
       " 'death': 88,\n",
       " 'congress': 89,\n",
       " 'now': 90,\n",
       " 'delhi': 91,\n",
       " 'plans': 92,\n",
       " 'this': 93,\n",
       " 'bihar': 94,\n",
       " 'staff': 95,\n",
       " 'security': 96,\n",
       " 'off': 97,\n",
       " 'talks': 98,\n",
       " 'one': 99,\n",
       " 'jk': 100,\n",
       " 'project': 101,\n",
       " 'mumbai': 102,\n",
       " 'day': 103,\n",
       " 'officials': 104,\n",
       " 'can': 105,\n",
       " 'kashmir': 106,\n",
       " 'drought': 107,\n",
       " 'i': 108,\n",
       " 'women': 109,\n",
       " 'time': 110,\n",
       " 'move': 111,\n",
       " 'bail': 112,\n",
       " 'work': 113,\n",
       " 'report': 114,\n",
       " 'arrested': 115,\n",
       " 'injured': 116,\n",
       " 'bank': 117,\n",
       " 'make': 118,\n",
       " 'murder': 119,\n",
       " 'takes': 120,\n",
       " 'road': 121,\n",
       " 'dead': 122,\n",
       " 'another': 123,\n",
       " 'kerala': 124,\n",
       " 'accused': 125,\n",
       " 'polls': 126,\n",
       " 'attack': 127,\n",
       " '10': 128,\n",
       " 'demand': 129,\n",
       " 'demands': 130,\n",
       " 'workers': 131,\n",
       " 'should': 132,\n",
       " 'protest': 133,\n",
       " 'net': 134,\n",
       " 'lakh': 135,\n",
       " 'but': 136,\n",
       " 'land': 137,\n",
       " 'his': 138,\n",
       " 'sp': 139,\n",
       " 'relief': 140,\n",
       " 'big': 141,\n",
       " 'leaders': 142,\n",
       " '4': 143,\n",
       " 'call': 144,\n",
       " 'under': 145,\n",
       " 'film': 146,\n",
       " 'order': 147,\n",
       " 'bill': 148,\n",
       " 'scam': 149,\n",
       " 'hospital': 150,\n",
       " 'tax': 151,\n",
       " '1': 152,\n",
       " 'world': 153,\n",
       " 'uti': 154,\n",
       " 'was': 155,\n",
       " 'you': 156,\n",
       " 'visit': 157,\n",
       " 'high': 158,\n",
       " 'militants': 159,\n",
       " 'hike': 160,\n",
       " 'three': 161,\n",
       " 'drive': 162,\n",
       " 'manipur': 163,\n",
       " 'policy': 164,\n",
       " 'house': 165,\n",
       " 'asks': 166,\n",
       " 'action': 167,\n",
       " 'say': 168,\n",
       " 'pay': 169,\n",
       " 'your': 170,\n",
       " 'school': 171,\n",
       " 'nda': 172,\n",
       " 'sept': 173,\n",
       " 'first': 174,\n",
       " 'still': 175,\n",
       " 'train': 176,\n",
       " 'we': 177,\n",
       " 'woman': 178,\n",
       " 'team': 179,\n",
       " 'aug': 180,\n",
       " 'wants': 181,\n",
       " 'education': 182,\n",
       " 'face': 183,\n",
       " 'funds': 184,\n",
       " 'special': 185,\n",
       " 'notice': 186,\n",
       " 'doctors': 187,\n",
       " 'again': 188,\n",
       " 'ban': 189,\n",
       " 'home': 190,\n",
       " 'fire': 191,\n",
       " 'crore': 192,\n",
       " 'their': 193,\n",
       " 'scheme': 194,\n",
       " 'college': 195,\n",
       " 'stir': 196,\n",
       " 'top': 197,\n",
       " 'people': 198,\n",
       " 'bid': 199,\n",
       " 'leader': 200,\n",
       " 'officers': 201,\n",
       " 'way': 202,\n",
       " 'blast': 203,\n",
       " 'youth': 204,\n",
       " 'ministers': 205,\n",
       " 'good': 206,\n",
       " 'bandh': 207,\n",
       " 'launch': 208,\n",
       " 'farmers': 209,\n",
       " 'central': 210,\n",
       " 'arrest': 211,\n",
       " 'health': 212,\n",
       " 'too': 213,\n",
       " 'cases': 214,\n",
       " 'system': 215,\n",
       " 'hits': 216,\n",
       " '5': 217,\n",
       " 'army': 218,\n",
       " 'law': 219,\n",
       " 'schools': 220,\n",
       " 'who': 221,\n",
       " 'tells': 222,\n",
       " 'men': 223,\n",
       " 'tomorrow': 224,\n",
       " 'poll': 225,\n",
       " 'bus': 226,\n",
       " 'four': 227,\n",
       " 'need': 228,\n",
       " 'industry': 229,\n",
       " 'punjab': 230,\n",
       " 'temple': 231,\n",
       " 'likely': 232,\n",
       " 'orders': 233,\n",
       " 'board': 234,\n",
       " 'drug': 235,\n",
       " 'yet': 236,\n",
       " 'threat': 237,\n",
       " 'denies': 238,\n",
       " 'bangalore': 239,\n",
       " 'aid': 240,\n",
       " 'what': 241,\n",
       " 'body': 242,\n",
       " 'begins': 243,\n",
       " 'party': 244,\n",
       " 'bengal': 245,\n",
       " 'rules': 246,\n",
       " 'services': 247,\n",
       " 'medical': 248,\n",
       " 'cpm': 249,\n",
       " 'old': 250,\n",
       " 'come': 251,\n",
       " 'better': 252,\n",
       " 'air': 253,\n",
       " 'mlas': 254,\n",
       " 'poor': 255,\n",
       " 'food': 256,\n",
       " 'act': 257,\n",
       " 'year': 258,\n",
       " 'market': 259,\n",
       " 'many': 260,\n",
       " 'musharraf': 261,\n",
       " 'traffic': 262,\n",
       " 'tehelka': 263,\n",
       " 'service': 264,\n",
       " 'love': 265,\n",
       " 'calls': 266,\n",
       " 'fake': 267,\n",
       " 'shot': 268,\n",
       " 'cabinet': 269,\n",
       " 'or': 270,\n",
       " 'civic': 271,\n",
       " 'hit': 272,\n",
       " 'hold': 273,\n",
       " 'varsity': 274,\n",
       " 'situation': 275,\n",
       " 'must': 276,\n",
       " 'karnataka': 277,\n",
       " 'check': 278,\n",
       " 'activists': 279,\n",
       " 'hurt': 280,\n",
       " 'seek': 281,\n",
       " 'give': 282,\n",
       " 'next': 283,\n",
       " 'support': 284,\n",
       " 'hurriyat': 285,\n",
       " 'makes': 286,\n",
       " 'among': 287,\n",
       " 'away': 288,\n",
       " 'that': 289,\n",
       " 'members': 290,\n",
       " 'open': 291,\n",
       " 'violence': 292,\n",
       " 'states': 293,\n",
       " 'gives': 294,\n",
       " 'award': 295,\n",
       " 'meeting': 296,\n",
       " 'being': 297,\n",
       " 'goes': 298,\n",
       " 'charges': 299,\n",
       " 'offer': 300,\n",
       " 'cops': 301,\n",
       " 'flood': 302,\n",
       " 'krishna': 303,\n",
       " 'red': 304,\n",
       " 'join': 305,\n",
       " 'keep': 306,\n",
       " 'than': 307,\n",
       " 'left': 308,\n",
       " 'public': 309,\n",
       " 'ai': 310,\n",
       " 'jail': 311,\n",
       " 'issues': 312,\n",
       " 'art': 313,\n",
       " 'crime': 314,\n",
       " '25': 315,\n",
       " 'end': 316,\n",
       " 'firm': 317,\n",
       " 'advani': 318,\n",
       " 'heart': 319,\n",
       " 'turns': 320,\n",
       " 'children': 321,\n",
       " 'seized': 322,\n",
       " 'singh': 323,\n",
       " 'patients': 324,\n",
       " 'rally': 325,\n",
       " 'family': 326,\n",
       " 'private': 327,\n",
       " 'supply': 328,\n",
       " 'before': 329,\n",
       " 'racket': 330,\n",
       " 'business': 331,\n",
       " '15': 332,\n",
       " 'gujarat': 333,\n",
       " 'stake': 334,\n",
       " 'play': 335,\n",
       " 'suicide': 336,\n",
       " 'parties': 337,\n",
       " 'sena': 338,\n",
       " 'do': 339,\n",
       " 'only': 340,\n",
       " 'july': 341,\n",
       " 'girl': 342,\n",
       " 'book': 343,\n",
       " 'decision': 344,\n",
       " 'look': 345,\n",
       " 'cms': 346,\n",
       " 'dont': 347,\n",
       " 'clean': 348,\n",
       " 'cut': 349,\n",
       " 'cricket': 350,\n",
       " 'launches': 351,\n",
       " 'fresh': 352,\n",
       " 'official': 353,\n",
       " 'railway': 354,\n",
       " 'rights': 355,\n",
       " 'colleges': 356,\n",
       " 'centres': 357,\n",
       " 'national': 358,\n",
       " 'gang': 359,\n",
       " 'summit': 360,\n",
       " 'simi': 361,\n",
       " 'stage': 362,\n",
       " 'peace': 363,\n",
       " '6': 364,\n",
       " 'custody': 365,\n",
       " 'change': 366,\n",
       " 'festival': 367,\n",
       " 'best': 368,\n",
       " 'airport': 369,\n",
       " 'test': 370,\n",
       " 'told': 371,\n",
       " 'office': 372,\n",
       " 'file': 373,\n",
       " 'former': 374,\n",
       " 'employees': 375,\n",
       " 'trinamul': 376,\n",
       " 'her': 377,\n",
       " 'free': 378,\n",
       " 'fight': 379,\n",
       " 'money': 380,\n",
       " 'orissa': 381,\n",
       " 'areas': 382,\n",
       " 'sales': 383,\n",
       " 'border': 384,\n",
       " 'want': 385,\n",
       " 'mishap': 386,\n",
       " 'sonia': 387,\n",
       " 'student': 388,\n",
       " 'ready': 389,\n",
       " 'lok': 390,\n",
       " 'kolkata': 391,\n",
       " 'stay': 392,\n",
       " 'just': 393,\n",
       " 'phone': 394,\n",
       " 'trade': 395,\n",
       " 'growth': 396,\n",
       " 'jaya': 397,\n",
       " 'assembly': 398,\n",
       " 'firing': 399,\n",
       " 'jammu': 400,\n",
       " 'continues': 401,\n",
       " 'units': 402,\n",
       " 'list': 403,\n",
       " 'station': 404,\n",
       " 'role': 405,\n",
       " 'cng': 406,\n",
       " 'programme': 407,\n",
       " 'needs': 408,\n",
       " 'oppn': 409,\n",
       " 'bollywood': 410,\n",
       " 'when': 411,\n",
       " 'ahead': 412,\n",
       " 'pune': 413,\n",
       " 'roads': 414,\n",
       " 'clash': 415,\n",
       " 'asked': 416,\n",
       " 'training': 417,\n",
       " 'illegal': 418,\n",
       " 'review': 419,\n",
       " 'assam': 420,\n",
       " 'major': 421,\n",
       " 'sought': 422,\n",
       " 'little': 423,\n",
       " 'council': 424,\n",
       " 'iday': 425,\n",
       " 'development': 426,\n",
       " 'comes': 427,\n",
       " 'use': 428,\n",
       " 'hope': 429,\n",
       " 'mps': 430,\n",
       " 'week': 431,\n",
       " 'worth': 432,\n",
       " 'crisis': 433,\n",
       " 'rise': 434,\n",
       " 'traders': 435,\n",
       " 'leave': 436,\n",
       " 'last': 437,\n",
       " 'rains': 438,\n",
       " 'vajpayee': 439,\n",
       " 'right': 440,\n",
       " 'busted': 441,\n",
       " 'vhp': 442,\n",
       " 'aids': 443,\n",
       " 'awards': 444,\n",
       " 'charge': 445,\n",
       " 'row': 446,\n",
       " 'ties': 447,\n",
       " 'price': 448,\n",
       " 'nod': 449,\n",
       " 'study': 450,\n",
       " 'projects': 451,\n",
       " 'naidu': 452,\n",
       " 'hands': 453,\n",
       " 'union': 454,\n",
       " 'making': 455,\n",
       " 'show': 456,\n",
       " '7': 457,\n",
       " 'moves': 458,\n",
       " 'quota': 459,\n",
       " '11': 460,\n",
       " 'put': 461,\n",
       " 'media': 462,\n",
       " 'rajnath': 463,\n",
       " 'khan': 464,\n",
       " '8': 465,\n",
       " 'legal': 466,\n",
       " 'ultras': 467,\n",
       " 'experts': 468,\n",
       " 'found': 469,\n",
       " 'management': 470,\n",
       " 'tourism': 471,\n",
       " 'car': 472,\n",
       " 'killing': 473,\n",
       " 'foreign': 474,\n",
       " 'ap': 475,\n",
       " 'sale': 476,\n",
       " 'antony': 477,\n",
       " 'sets': 478,\n",
       " 'bomb': 479,\n",
       " 'begin': 480,\n",
       " 'ordered': 481,\n",
       " 'ayodhya': 482,\n",
       " 'die': 483,\n",
       " 'residents': 484,\n",
       " 'green': 485,\n",
       " 'banks': 486,\n",
       " 'tdp': 487,\n",
       " 'enron': 488,\n",
       " 'six': 489,\n",
       " 'election': 490,\n",
       " 'music': 491,\n",
       " 'heavy': 492,\n",
       " 'naga': 493,\n",
       " 'firms': 494,\n",
       " 'bodies': 495,\n",
       " 'telecom': 496,\n",
       " 'sinha': 497,\n",
       " 'mch': 498,\n",
       " 'norms': 499,\n",
       " 'mysore': 500,\n",
       " 'oil': 501,\n",
       " 'suspended': 502,\n",
       " 'transfer': 503,\n",
       " 'urges': 504,\n",
       " 'they': 505,\n",
       " 'young': 506,\n",
       " 'star': 507,\n",
       " 'through': 508,\n",
       " 'hearing': 509,\n",
       " 'opens': 510,\n",
       " 'dept': 511,\n",
       " 'some': 512,\n",
       " 'bmc': 513,\n",
       " 'schemes': 514,\n",
       " 'news': 515,\n",
       " 'sector': 516,\n",
       " 'shah': 517,\n",
       " 'session': 518,\n",
       " 'political': 519,\n",
       " 'offers': 520,\n",
       " 'software': 521,\n",
       " 'china': 522,\n",
       " 'appointment': 523,\n",
       " 'run': 524,\n",
       " 'august': 525,\n",
       " 'discuss': 526,\n",
       " 'here': 527,\n",
       " 'mobile': 528,\n",
       " 'threaten': 529,\n",
       " 'faces': 530,\n",
       " 'surat': 531,\n",
       " 'taking': 532,\n",
       " 'camp': 533,\n",
       " 'how': 534,\n",
       " 'caught': 535,\n",
       " 'post': 536,\n",
       " 'drugs': 537,\n",
       " 'pollution': 538,\n",
       " 'my': 539,\n",
       " 'committee': 540,\n",
       " 'terrorism': 541,\n",
       " 'doctor': 542,\n",
       " 'warns': 543,\n",
       " 'rbi': 544,\n",
       " 'problems': 545,\n",
       " 'eye': 546,\n",
       " 'west': 547,\n",
       " 'trains': 548,\n",
       " 'child': 549,\n",
       " 'tn': 550,\n",
       " 'why': 551,\n",
       " 'till': 552,\n",
       " 'pms': 553,\n",
       " 'trouble': 554,\n",
       " 'buy': 555,\n",
       " 'me': 556,\n",
       " 'govts': 557,\n",
       " '20': 558,\n",
       " 'badal': 559,\n",
       " 'space': 560,\n",
       " 'mp': 561,\n",
       " 'lake': 562,\n",
       " 'financial': 563,\n",
       " 'exports': 564,\n",
       " 'missing': 565,\n",
       " 'courses': 566,\n",
       " 'claims': 567,\n",
       " 'flays': 568,\n",
       " 'chairman': 569,\n",
       " 'district': 570,\n",
       " 'tv': 571,\n",
       " 'small': 572,\n",
       " 'continue': 573,\n",
       " 'cable': 574,\n",
       " 'during': 575,\n",
       " 'industrial': 576,\n",
       " 'hot': 577,\n",
       " 'alert': 578,\n",
       " 'due': 579,\n",
       " 'urged': 580,\n",
       " 'control': 581,\n",
       " 'rain': 582,\n",
       " 'msu': 583,\n",
       " 'cant': 584,\n",
       " 'fails': 585,\n",
       " 'status': 586,\n",
       " 'eyes': 587,\n",
       " 'if': 588,\n",
       " 'results': 589,\n",
       " 'forces': 590,\n",
       " '100': 591,\n",
       " 'arms': 592,\n",
       " 'indopak': 593,\n",
       " 'boost': 594,\n",
       " 'steps': 595,\n",
       " 'dpc': 596,\n",
       " 'auto': 597,\n",
       " 'ends': 598,\n",
       " 'tribals': 599,\n",
       " 'wont': 600,\n",
       " 'protests': 601,\n",
       " 'militant': 602,\n",
       " 'meets': 603,\n",
       " 'were': 604,\n",
       " 'term': 605,\n",
       " 'global': 606,\n",
       " 'wto': 607,\n",
       " 'war': 608,\n",
       " 'course': 609,\n",
       " 'response': 610,\n",
       " 'launched': 611,\n",
       " 'ganguly': 612,\n",
       " 'joins': 613,\n",
       " 'ganesh': 614,\n",
       " '12': 615,\n",
       " 'workshop': 616,\n",
       " 'policemen': 617,\n",
       " '13': 618,\n",
       " 'notices': 619,\n",
       " 'others': 620,\n",
       " 'straight': 621,\n",
       " 'liquor': 622,\n",
       " 'mamata': 623,\n",
       " 'released': 624,\n",
       " 'mla': 625,\n",
       " 'park': 626,\n",
       " 'lives': 627,\n",
       " 'safe': 628,\n",
       " 'pvt': 629,\n",
       " 'planned': 630,\n",
       " 'dharna': 631,\n",
       " 'duty': 632,\n",
       " 'south': 633,\n",
       " 'ministry': 634,\n",
       " 'rss': 635,\n",
       " 'stand': 636,\n",
       " 'closure': 637,\n",
       " 'between': 638,\n",
       " 'rail': 639,\n",
       " 'campus': 640,\n",
       " 'close': 641,\n",
       " 'opposes': 642,\n",
       " 'rural': 643,\n",
       " 'attacks': 644,\n",
       " 'unit': 645,\n",
       " 'compensation': 646,\n",
       " 'made': 647,\n",
       " 'delay': 648,\n",
       " 'toll': 649,\n",
       " 'release': 650,\n",
       " 'tariff': 651,\n",
       " 'laws': 652,\n",
       " 'jharkhand': 653,\n",
       " 'return': 654,\n",
       " 'rupee': 655,\n",
       " 'agra': 656,\n",
       " 'officer': 657,\n",
       " 'victims': 658,\n",
       " 'stop': 659,\n",
       " 'tour': 660,\n",
       " 'cag': 661,\n",
       " 'lu': 662,\n",
       " 'villages': 663,\n",
       " 'cell': 664,\n",
       " 'bcc': 665,\n",
       " 'tough': 666,\n",
       " 'fall': 667,\n",
       " 'days': 668,\n",
       " 'focus': 669,\n",
       " 'houses': 670,\n",
       " 'without': 671,\n",
       " '9': 672,\n",
       " 'lucknow': 673,\n",
       " 'draws': 674,\n",
       " 'mcd': 675,\n",
       " 'campaign': 676,\n",
       " 'districts': 677,\n",
       " 'maharashtra': 678,\n",
       " 'defence': 679,\n",
       " 'fee': 680,\n",
       " 'rly': 681,\n",
       " 'director': 682,\n",
       " 'bsp': 683,\n",
       " 'could': 684,\n",
       " 'haryana': 685,\n",
       " 'seats': 686,\n",
       " 'quake': 687,\n",
       " 'rule': 688,\n",
       " 'economy': 689,\n",
       " 'governor': 690,\n",
       " 'promises': 691,\n",
       " 'does': 692,\n",
       " 'dies': 693,\n",
       " 'keeps': 694,\n",
       " 'pact': 695,\n",
       " 'kapoor': 696,\n",
       " 'tackle': 697,\n",
       " 'cards': 698,\n",
       " 'improve': 699,\n",
       " 'raise': 700,\n",
       " 'remanded': 701,\n",
       " 'sex': 702,\n",
       " 'petition': 703,\n",
       " 'he': 704,\n",
       " 'head': 705,\n",
       " 'theatre': 706,\n",
       " 'low': 707,\n",
       " '14': 708,\n",
       " 'revive': 709,\n",
       " 'zp': 710,\n",
       " 'courts': 711,\n",
       " 'mother': 712,\n",
       " 'kills': 713,\n",
       " 'hai': 714,\n",
       " 'prices': 715,\n",
       " 'holds': 716,\n",
       " 'turn': 717,\n",
       " 'vc': 718,\n",
       " 'elections': 719,\n",
       " 'leaves': 720,\n",
       " 'owners': 721,\n",
       " 'cost': 722,\n",
       " 'kumar': 723,\n",
       " 'deal': 724,\n",
       " 'encounter': 725,\n",
       " 'kutch': 726,\n",
       " 'films': 727,\n",
       " 'fund': 728,\n",
       " 'given': 729,\n",
       " 'bags': 730,\n",
       " 'seminar': 731,\n",
       " 'threatens': 732,\n",
       " 'watch': 733,\n",
       " 'decide': 734,\n",
       " 'loan': 735,\n",
       " 'laloo': 736,\n",
       " 'patna': 737,\n",
       " 'bellary': 738,\n",
       " 'girls': 739,\n",
       " 'remain': 740,\n",
       " '30': 741,\n",
       " 'find': 742,\n",
       " 'five': 743,\n",
       " '50': 744,\n",
       " 'years': 745,\n",
       " 'treatment': 746,\n",
       " 'reliance': 747,\n",
       " 'corruption': 748,\n",
       " 'wb': 749,\n",
       " 'provide': 750,\n",
       " 'panchayat': 751,\n",
       " 'boy': 752,\n",
       " 'nabbed': 753,\n",
       " 'paper': 754,\n",
       " 'operators': 755,\n",
       " 'sebi': 756,\n",
       " 'future': 757,\n",
       " 'malaria': 758,\n",
       " 'near': 759,\n",
       " 'behind': 760,\n",
       " 'building': 761,\n",
       " 'ncp': 762,\n",
       " 'hand': 763,\n",
       " 'online': 764,\n",
       " 'railways': 765,\n",
       " 'announces': 766,\n",
       " 'safety': 767,\n",
       " 'citizens': 768,\n",
       " 'blasts': 769,\n",
       " 'scientists': 770,\n",
       " 'trial': 771,\n",
       " 'b': 772,\n",
       " 'nhrc': 773,\n",
       " 'code': 774,\n",
       " 'most': 775,\n",
       " 'judicial': 776,\n",
       " 'well': 777,\n",
       " 'failure': 778,\n",
       " 'finds': 779,\n",
       " 'quit': 780,\n",
       " 'black': 781,\n",
       " 'aiims': 782,\n",
       " 'research': 783,\n",
       " 'droughthit': 784,\n",
       " 'see': 785,\n",
       " 'oppose': 786,\n",
       " 'property': 787,\n",
       " 'our': 788,\n",
       " 'plant': 789,\n",
       " 'bad': 790,\n",
       " 'rises': 791,\n",
       " 'kill': 792,\n",
       " 'never': 793,\n",
       " 'getting': 794,\n",
       " 'concern': 795,\n",
       " 'president': 796,\n",
       " 'lack': 797,\n",
       " 'part': 798,\n",
       " 'puts': 799,\n",
       " 'double': 800,\n",
       " 'm': 801,\n",
       " 'wife': 802,\n",
       " 'full': 803,\n",
       " 'form': 804,\n",
       " 'enter': 805,\n",
       " 'fashion': 806,\n",
       " 'reforms': 807,\n",
       " 'seat': 808,\n",
       " 'opposed': 809,\n",
       " 'blames': 810,\n",
       " 'deals': 811,\n",
       " 'hospitals': 812,\n",
       " 's': 813,\n",
       " 'target': 814,\n",
       " 'floods': 815,\n",
       " 'flights': 816,\n",
       " 'town': 817,\n",
       " 'phoolan': 818,\n",
       " 'junior': 819,\n",
       " 'dal': 820,\n",
       " 'science': 821,\n",
       " 'like': 822,\n",
       " 'age': 823,\n",
       " 'ls': 824,\n",
       " 'deaths': 825,\n",
       " 'so': 826,\n",
       " 'become': 827,\n",
       " 'shops': 828,\n",
       " 'ia': 829,\n",
       " 'contest': 830,\n",
       " 'construction': 831,\n",
       " 'talk': 832,\n",
       " 'human': 833,\n",
       " 'where': 834,\n",
       " 'going': 835,\n",
       " 'jaswant': 836,\n",
       " 'birthday': 837,\n",
       " 'ceasefire': 838,\n",
       " 'fdi': 839,\n",
       " 'awareness': 840,\n",
       " 'brings': 841,\n",
       " 'vehicles': 842,\n",
       " 'cpi': 843,\n",
       " 'rate': 844,\n",
       " 'tea': 845,\n",
       " 'recovered': 846,\n",
       " 'had': 847,\n",
       " 'sachin': 848,\n",
       " 'group': 849,\n",
       " 'debate': 850,\n",
       " 'tata': 851,\n",
       " 'loss': 852,\n",
       " 'months': 853,\n",
       " 'bsnl': 854,\n",
       " 'indias': 855,\n",
       " 'bar': 856,\n",
       " 'wins': 857,\n",
       " 'style': 858,\n",
       " 'anil': 859,\n",
       " 'kids': 860,\n",
       " 'starvation': 861,\n",
       " 'n': 862,\n",
       " 'proposal': 863,\n",
       " 'indians': 864,\n",
       " 'jobs': 865,\n",
       " 'lab': 866,\n",
       " 'care': 867,\n",
       " 'son': 868,\n",
       " 'force': 869,\n",
       " 'sees': 870,\n",
       " 'kannada': 871,\n",
       " 'success': 872,\n",
       " 'line': 873,\n",
       " 'own': 874,\n",
       " 'telangana': 875,\n",
       " 'early': 876,\n",
       " 'visits': 877,\n",
       " 'samata': 878,\n",
       " 'bridge': 879,\n",
       " 'exam': 880,\n",
       " 'expert': 881,\n",
       " 'job': 882,\n",
       " 'name': 883,\n",
       " 'higher': 884,\n",
       " 'start': 885,\n",
       " 'times': 886,\n",
       " 'total': 887,\n",
       " 'gold': 888,\n",
       " '21': 889,\n",
       " 'together': 890,\n",
       " 'battle': 891,\n",
       " 'admissions': 892,\n",
       " 'rejects': 893,\n",
       " 'attacked': 894,\n",
       " 'lose': 895,\n",
       " 'social': 896,\n",
       " 'around': 897,\n",
       " 'finance': 898,\n",
       " 'number': 899,\n",
       " 'club': 900,\n",
       " 'villagers': 901,\n",
       " 'killings': 902,\n",
       " 'other': 903,\n",
       " 'chautala': 904,\n",
       " 'problem': 905,\n",
       " 'uk': 906,\n",
       " 'petrol': 907,\n",
       " 'politics': 908,\n",
       " 'controversy': 909,\n",
       " 'real': 910,\n",
       " 'friends': 911,\n",
       " 'krushi': 912,\n",
       " 'talking': 913,\n",
       " 'win': 914,\n",
       " 'shortage': 915,\n",
       " 'task': 916,\n",
       " 'happy': 917,\n",
       " 'second': 918,\n",
       " 'fail': 919,\n",
       " 'area': 920,\n",
       " 'investors': 921,\n",
       " 'march': 922,\n",
       " 'cuts': 923,\n",
       " 'stays': 924,\n",
       " 'dd': 925,\n",
       " 'lawyers': 926,\n",
       " 'justice': 927,\n",
       " 'them': 928,\n",
       " 'cause': 929,\n",
       " 'dalit': 930,\n",
       " 'operation': 931,\n",
       " 'slowdown': 932,\n",
       " 'ias': 933,\n",
       " 'block': 934,\n",
       " 'institute': 935,\n",
       " 'chaos': 936,\n",
       " 'lagaan': 937,\n",
       " 'protect': 938,\n",
       " 'export': 939,\n",
       " 'rice': 940,\n",
       " 'agenda': 941,\n",
       " 'let': 942,\n",
       " 'fair': 943,\n",
       " 'labour': 944,\n",
       " '17': 945,\n",
       " 'files': 946,\n",
       " '18': 947,\n",
       " 'village': 948,\n",
       " 'pc': 949,\n",
       " 'engineers': 950,\n",
       " 'remarks': 951,\n",
       " 'parents': 952,\n",
       " 'contract': 953,\n",
       " 'vmc': 954,\n",
       " 'baby': 955,\n",
       " 'passes': 956,\n",
       " 'phoolans': 957,\n",
       " 'saffronisation': 958,\n",
       " 'got': 959,\n",
       " 'ganesha': 960,\n",
       " 'boomtown': 961,\n",
       " 'burqa': 962,\n",
       " 'adjourned': 963,\n",
       " 'live': 964,\n",
       " 'coming': 965,\n",
       " 'river': 966,\n",
       " 'government': 967,\n",
       " 'isi': 968,\n",
       " 'record': 969,\n",
       " 'cheating': 970,\n",
       " 'letter': 971,\n",
       " 'mulayam': 972,\n",
       " 'package': 973,\n",
       " 'revenue': 974,\n",
       " 'dream': 975,\n",
       " 'commits': 976,\n",
       " 'invest': 977,\n",
       " 'statement': 978,\n",
       " 'classes': 979,\n",
       " 'privatisation': 980,\n",
       " 'mental': 981,\n",
       " 'place': 982,\n",
       " 'claim': 983,\n",
       " 'side': 984,\n",
       " 'truck': 985,\n",
       " 'guns': 986,\n",
       " 'despite': 987,\n",
       " 'steel': 988,\n",
       " 'production': 989,\n",
       " 'fear': 990,\n",
       " 'vehicle': 991,\n",
       " 'reserves': 992,\n",
       " 'fardeen': 993,\n",
       " 'hopes': 994,\n",
       " 'womens': 995,\n",
       " 'bsf': 996,\n",
       " 'fernandes': 997,\n",
       " 'along': 998,\n",
       " 'kargil': 999,\n",
       " 'criminal': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No', 'deadline', 'for', 'tax', 'exempt,', 'can', 'take', 'on', 'these', 'options', 'advantage', 'of', 'discounts']\n"
     ]
    }
   ],
   "source": [
    "from googletrans import Translator\n",
    "translator = Translator()\n",
    "translated = translator.translate('        ,         ').text.split(\" \")\n",
    "print(translated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['no', 'deadline', 'for', 'tax', 'can', 'take', 'on', 'these', 'options', 'advantage', 'of']\n"
     ]
    }
   ],
   "source": [
    "f=[]\n",
    "for i in translated:\n",
    "    i=i.lower()\n",
    "    if i in tokenizer.word_index.keys():\n",
    "        f.append(i)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no deadline for tax can take on these options advantage of'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f=\" \".join(f)\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 7)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test1 = tokenizer.texts_to_sequences(f)\n",
    "x_test1= pad_sequences(x_test1,7)\n",
    "x_test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=model.predict(x_test1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
